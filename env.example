# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_EMBEDDING_MODEL=text-embedding-3-large
OPENAI_CHAT_MODEL=gpt-4o

# Ollama Configuration
OLLAMA_API_BASE=http://localhost:11434
OLLAMA_CHAT_MODEL=alibayram/medgemma
OLLAMA_EMBEDDING_MODEL=embeddinggemma

# Vector Database Configuration
CHROMA_PERSIST_DIRECTORY=./chroma_db
COLLECTION_NAME=pedir_knowledge_base

# Retrieval Configuration
TOP_K_RETRIEVAL=5
HYBRID_ALPHA=0.7  # Weight for semantic search (1-alpha for BM25)

# Embedding Model Configuration
EMBEDDING_PROVIDER=openai  # openai, sentence-transformer, or ollama
SENTENCE_TRANSFORMER_MODEL=BAAI/bge-m3

# LLM Provider Configuration
LLM_PROVIDER=openai  # openai or ollama

# Application Settings
LOG_LEVEL=INFO
MAX_CHUNK_SIZE=300  # For embeddinggemma use 300, for larger models can use 512-768
CHUNK_OVERLAP=50
MIN_RELEVANCE_SCORE=0.4  # Minimum similarity score for retrieval (0.0-1.0)

